import{_ as d,c as m,a3 as n,j as i,G as a,w as o,B as l,o as k,a as t}from"./chunks/framework.BaR4VHXY.js";const g=JSON.parse('{"title":"大数据","description":"","frontmatter":{"Created at":"2019-05-21T00:00:00.000Z","Last updated at":"2019-05-24T00:00:00.000Z","tags":["大数据"]},"headers":[],"relativePath":"zh-CN/学习笔记/大数据.md","filePath":"zh-CN/学习笔记/大数据.md","lastUpdated":null}'),_={name:"zh-CN/学习笔记/大数据.md"};function v(f,e,u,c,b,H){const r=l("name"),s=l("value"),p=l("property"),h=l("description");return k(),m("div",null,[e[17]||(e[17]=n('<h1 id="大数据" tabindex="-1">大数据 <a class="header-anchor" href="#大数据" aria-label="Permalink to &quot;大数据&quot;">​</a></h1><h2 id="大数据-1" tabindex="-1">大数据 <a class="header-anchor" href="#大数据-1" aria-label="Permalink to &quot;大数据&quot;">​</a></h2><h4 id="streamingpro简介" tabindex="-1">streamingPro简介 <a class="header-anchor" href="#streamingpro简介" aria-label="Permalink to &quot;streamingPro简介&quot;">​</a></h4><p><a href="https://github.com/allwefantasy/streamingpro" target="_blank" rel="noreferrer">StreamingPro</a>主要设计为在Apache Spark上运行，但它也支持运行在Apache FLink。因此，它可以被认为是一个跨平台的分布式平台，它是大数据（BigData）平台和人工智能（AI）平台的结合，可以运行大数据处理和机器学习脚本。这个项目的作者是祝威廉 特征： ![[../_resources/unknown_filename-42d6141b.png]] 体系架构： ![[../_resources/unknown_filename-0d91115a.png]]</p><h4 id="环境准备" tabindex="-1">环境准备 <a class="header-anchor" href="#环境准备" aria-label="Permalink to &quot;环境准备&quot;">​</a></h4><p>本次安装需要三台虚拟机，选用的操作系统版本是contos6.9 64位。(虽然StreamingPro只依赖spark，但是本次安装还是将hadoop相关的其他组件一并安装，方便后续使用，例如hbase和hive等) 各组件在三台机器上的分布情况如下： JDK ：Hadoop和Spark 依赖的配置. Scala：Spark依赖的配置，建议版本不低于spark的版本。 Hadoop: 是一个分布式系统基础架构。 Spark: 分布式存储的大数据进行处理的工具。 zookeeper:分布式应用程序协调服务，HBase集群需要。 HBase: 一个结构化数据的分布式存储系统。 Hive: 基于Hadoop的一个数据仓库工具，目前的默认元数据库是mysql。 Kafka:分布式消息队列</p><h4 id="集群的相关配置" tabindex="-1">集群的相关配置 <a class="header-anchor" href="#集群的相关配置" aria-label="Permalink to &quot;集群的相关配置&quot;">​</a></h4><p>下面前5步操作可以先在一台虚拟机上操作，然后克隆出另外两台机器。</p><ol><li>关闭防火墙及关闭操作系统安全访问控制 说明:其实可以不关闭防火墙，进行权限设置，但是为了方便访问，于是便关闭了防火墙。每个机器都做！！！ 永久关闭防火墙: chkconfig iptables off 说明：操作系统默认是打开安全访问控制的，这样会导致部分软件安装配置失败，为了方便，我们将它关闭。 查看SELinux状态 getenforce 修改配置文件/etc/selinux/config 将SELINUX=enforcing改为SELINUX=disabled</li></ol><ul><li><p>修改系统网络配置 配置固定ip地址和dns服务器地址，保证主机能上网。</p></li><li><p>调整系统时区及时间配置 首先将时区调整到东八区，保险起见再执行一下下面的命令 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 集群上的机器时间要同步，我们可以将所有的机器跟集群中某台机器进行时间同步。也可以简单的跟互联网授时服务器同步。 ntpdate pool.ntp.org</p></li><li><p>安装java和scala基础环境及修改系统环境变量 安装jdk1.8 解压缩jdk安装包 tar zxvf jdk-8u144-linux-x64.tar.gz 创建目录/opt/java mkdir /opt/java 移动文件夹jdk1.8.0_144到/opt/jdk下面，并改名为jdk1.8 mv jdk1.8.0_144/ /opt/jdk/jdk1.8 安装scala2.12.2 tar zxvf scala-2.12.2.tgz 创建目录/opt/scala mkdir /opt/scala 移动文件夹scala-2.12.2到/opt/ scala下面，并改名为scala2.12.2 mv scala-2.12.2 /opt/scala/scala2.12.2 在 /etc/profile 这个配置文件要添加很多的环境配置，这里就先将整体的环境配置列举出来，各位在配置环境变量的以自己的为准！！！ 可以先配置好环境变量之后，在传输到其他机器上去。 source /etc/profile</p><p>#Java Config export JAVA_HOME=/opt/java/jdk1.8 export JRE_HOME=/opt/java/jdk1.8/jre export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib</p><h1 id="scala-config" tabindex="-1">Scala Config <a class="header-anchor" href="#scala-config" aria-label="Permalink to &quot;Scala Config&quot;">​</a></h1><p>export SCALA_HOME=/opt/scala/scala2.12.2</p><h1 id="spark-config" tabindex="-1">Spark Config <a class="header-anchor" href="#spark-config" aria-label="Permalink to &quot;Spark Config&quot;">​</a></h1><p>export SPARK_HOME=/opt/spark/spark2.2</p><h1 id="zookeeper-config" tabindex="-1">Zookeeper Config <a class="header-anchor" href="#zookeeper-config" aria-label="Permalink to &quot;Zookeeper Config&quot;">​</a></h1><p>export ZK_HOME=/opt/zookeeper/zookeeper3.4</p><h1 id="hbase-config" tabindex="-1">HBase Config <a class="header-anchor" href="#hbase-config" aria-label="Permalink to &quot;HBase Config&quot;">​</a></h1><p>export HBASE_HOME=/opt/hbase/hbase1.2</p><h1 id="hadoop-config" tabindex="-1">Hadoop Config <a class="header-anchor" href="#hadoop-config" aria-label="Permalink to &quot;Hadoop Config&quot;">​</a></h1><p>export HADOOP_HOME=/opt/hadoop/hadoop2.8 export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib&quot;</p><h1 id="hive-config" tabindex="-1">Hive Config <a class="header-anchor" href="#hive-config" aria-label="Permalink to &quot;Hive Config&quot;">​</a></h1><p>export HIVE_HOME=/opt/hive/hive2.1 export HIVE_CONF_DIR=${HIVE_HOME}/conf #kafka config export KAFKA_HOME=/opt/kafka/kafka1.0.0</p><p>export PATH=.😒{JAVA_HOME}/bin:${SCALA_HOME}/bin:${SPARK_HOME}/bin:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:${ZK_HOME}/bin:${HBASE_HOME}/bin:${HIVE_HOME}/bin:${KAFKA_HOME}/bin:$PATH</p></li></ul><ol start="5"><li>主机名更改以及主机和IP做相关映射 说明:更改主机名是为了方便集群管理，不然每个机器的名称都叫localhost也不太好吧！ 集群所有的机器都要做这个操作。 输入 vim /etc/sysconfig/network 将localhost.localdomain修改为你要更改的名称，每台名称都不一样 例如: HOSTNAME=master 主机名和IP的关系映射 修改hosts文件，做关系映射 说明:这个每台机器都做这个配置，具体ip和主机名称以自己的为准。 输入: vim /etc/hosts 添加 192.168.124.201 master 192.168.124.202 slave1 192.168.124.203 slave2 重启机器，开始克隆另外两台机器slave1,slave2,值得注意的是克隆完之后修改修改ip地址和主机名。</li><li>ssh免密登录 设置ssh免密码登录是为了操作方便 生成秘钥文件 在每台机器上都执行一遍 首先输入: ssh-keygen -t rsa -P &#39;&#39; 生成秘钥之后，然后将每台机器/root/.ssh 都存入内容相同的文件，文件名称叫authorized_keys，文件内容是我们刚才为3台机器生成的公钥。可以在一台机器上生成，然后复制到其它的机器上。 新建authorized_keys文件 输入 : touch /root/.ssh/authorized_keys 编辑 authorized_keys 并将其他机器上的秘钥拷贝过来 cat /root/.ssh/id_rsa.pub vim /root/.ssh/authorized_keys 将其它机器上的 id_rsa.pub 的内容拷贝到 authorized_keys这个文件中。 最终authorized_keys文件的内容 将这个最终的authorized_keys文件copy到其他机器的 /root/.ssh 目录下。使用scp或者ftp都可以。 scp命令示例: scp -r /root/.ssh/authorized_keys root@slave1:/root/.ssh scp -r /root/.ssh/authorized_keys root@slave2:/root/.ssh 测试免密码登录 输入: ssh slave1 ssh slave2 输入 exit 退出</li></ol><h4 id="开始安装环境" tabindex="-1">开始安装环境 <a class="header-anchor" href="#开始安装环境" aria-label="Permalink to &quot;开始安装环境&quot;">​</a></h4><h5 id="hadoop的环境搭建" tabindex="-1">Hadoop的环境搭建 <a class="header-anchor" href="#hadoop的环境搭建" aria-label="Permalink to &quot;Hadoop的环境搭建&quot;">​</a></h5><p>事先说明，这些配置可以在一台机器上配置，然后复制到其他机器上就行了。复制之后注意使这些配置文件生效。</p><ol><li>hadoop配置 1.1. 文件准备 将下载下来的Hadoop的配置文件进行解压 在linux上输入: tar -xvf hadoop-2.8.2.tar.gz 然后将解压之后的文件夹移动到opt/hadoop文件夹下，没有该文件夹就新建，然后将文件夹重命名为hadoop2.8。 mkdir /opt/hadoop 在linux上输入移动文件夹命令: mv hadoop-2.8.2 /opt/hadoop/hadoop2.8 1.2. 修改配置文件 修改 core-site.xml、hadoop-env.sh、hdfs-site.xml、mapred-site.xml 等这些配置文件 在linux输入进入该目录的命令： cd /opt/hadoop/hadoop2.8/etc/hadoop 1.2.1. 修改 core-site.xml hadoop的存放路径可以自行更改。开始我以为这些文件夹需要手动创建，后来实践了，如果不手动创建，会自动创建的，所以就去掉了手动创建目录的步骤。 输入: vim core-site.xml</li></ol><p>说明: fs.defaultFS 是缺省文件的名称， 最早使用的是 fs.default.name，后来在最新官方文档中查到该方法已经弃用了。于是边改成这个了。ps：感觉也没啥区别。 1.2.2. 修改 hadoop-env.sh export JAVA_HOME=${JAVA_HOME} 修改为： export JAVA_HOME=/opt/java/jdk1.8 注:修改为自己JDK的路径 1.2.3. 修改 hdfs-site.xml 下面的hdfs的存放路径，可以根据自己机器更改。</p><p>1.2.4. 修改mapred-site.xml 执行mapreduce的运行框架配置。ps:感觉这个配置没啥用，可能我没用mr吧。 如果没有 mapred-site.xml 该文件，就复制mapred-site.xml.template文件并重命名为mapred-site.xml。 修改这个新建的mapred-site.xml文件</p><p>1.2.5. 修改yarn-site.xml文件 yarn 资源调度的配置，集群的话这个配置是必须的。 修改/opt/hadoop/hadoop2.8/etc/hadoop/yarn-site.xml文件，</p><p>说明：yarn.nodemanager.vmem-check-enabled这个的意思是忽略虚拟内存的检查，如果你是安装在虚拟机上，这个配置很有用，配上去之后后续操作不容易出问题。如果是实体机上，并且内存够多，可以将这个配置去掉。 1.2.6. 修改slaves 设置主从的配置。如果不设置这个，集群就无法得知主从了。如果是单机模式，就没必要配置了。 修改/opt/hadoop/hadoop2.8/etc/hadoop/slaves文件 更改为 slave1 slave2 在一台机器上(最好是master)做完这些配置之后，我们使用scp命令将这些配置传输到其他机器上。 输入: hadoop环境传输 scp -r /opt/hadoop root@slave1:/opt scp -r /opt/hadoop root@slave2:/opt 传输之后，便在主节点启动集群。 在启动hadoop之前，需要初始化，这个只需要在master上初始化就可以了。 2. hadoop启动 注:启动hadoop之前确保防火墙关闭，各个机器时间通过，ssh免登录都没问题。 初始化hadoop （第一次启动hadoop集群时格式化） 切换到/opt/hadoop/hadoop2.8/bin目录下输入 ./hdfs namenode -format 初始化成功之后，切换到/opt/hadoop/hadoop2.8/sbin 启动hadoop 的hdfs和yarn 输入: start-dfs.sh start-yarn.sh 第一次登录会询问是否连接，输入yes ，然后输入密码就可以了 启动成功之后，可以使用jps命令在各个机器上查看是否成功 可以在浏览器输入: ip+50070 和8088端口查看 <a href="http://master:50070" target="_blank" rel="noreferrer">http://master:50070</a><a href="http://master:8088/cluster" target="_blank" rel="noreferrer">http://master:8088/cluster</a> 若如图显示，则启动成功。 若失败，检查jps是否成功启动，防火墙是否都关闭。都确认没问题之后，还是无法打开界面，请查看日志，再来找原因。 测试： 上传文件到hdfs：hadoop fs -put linux系统文件 hadoop路径 下载文件到本地：hadoop fs -get /tmp/qy88.txt . 删除文件：hadoop fs -rm /tmp/qy87bigfile.txt 创建文件夹：hadoop fs -mkdir /tmp/qy87 删除文件夹：hadoop fs -rmr /tmp/qy87 检查文件是否存在,存在返回0，不存在返回1 常见问题： 19/02/14 14:50:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 如果报上面的警告，原因是系统默认的glibc库是2.12版本，而hadoop期望是2.14版本。 解决办法，在hadoop的log4J配置文件/opt/hadoop/hadoop2.8/etc/hadoop/log4j.properties中加入: log4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR master和slave1以及slave2三台机器都要修改。 重启hadoop服务即可。</p><h5 id="spark的环境配置" tabindex="-1">Spark的环境配置 <a class="header-anchor" href="#spark的环境配置" aria-label="Permalink to &quot;Spark的环境配置&quot;">​</a></h5><ol><li><p>文件准备 将下载好的Spark文件解压 输入 tar zxvf spark-2.2.0-bin-hadoop2.7.tgz 然后移动到/opt/spark 里面，并重命名 输入 mkdir /opt/spark mv spark-2.2.0-bin-hadoop2.7 /opt/spark/spark2.2</p></li><li><p>更改配置文件 切换目录 输入: cd /opt/spark/spark2.2/conf/ 2.1 修改 spark-env.sh 在conf目录下，修改spark-env.sh文件，如果没有 spark-env.sh 该文件，就复制spark-env.sh.template文件并重命名为spark-env.sh。 修改这个新建的spark-env.sh文件，加入配置:</p><p>export SCALA_HOME=/opt/scala/scala2.12.2<br> export JAVA_HOME=/opt/java/jdk1.8 export HADOOP_HOME=/opt/hadoop/hadoop2.8<br> export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop<br> export SPARK_HOME=/opt/spark/spark2.2 export SPARK_MASTER_IP=master<br> export SPARK_EXECUTOR_MEMORY=4G</p></li></ol><p>注:上面的路径以自己的为准，SPARK_MASTER_IP为主机，SPARK_EXECUTOR_MEMORY为设置的运行内存。 2.2 修改slaves slaves 分布式文件 在conf目录下，修改slaves文件，如果没有 slaves 该文件，就复制slaves .template文件并重命名为slaves 。 修改这个新建的slaves 文件，加入配置: slave1 slave2 在一台机器上(最好是master)做完这些配置之后，我们使用scp命令将这些配置传输到其他机器上。 spark环境传输 scp -r /opt/spark root@slave1:/opt scp -r /opt/spark root@slave2:/opt 传输之后，便在主节点启动集群。 3. spark启动 说明:要先启动Hadoop 切换到Spark目录下 输入: cd /opt/spark/spark2.2/sbin 然后启动Spark 输入: start-all.sh 启动成功之后，可以使用jps命令在各个机器上查看是否成功。 可以在浏览器输入: ip+8080 端口查看 若成功显示这个界面，则表示Spark成功启动。</p><h5 id="zookeeper的环境配置" tabindex="-1">Zookeeper的环境配置 <a class="header-anchor" href="#zookeeper的环境配置" aria-label="Permalink to &quot;Zookeeper的环境配置&quot;">​</a></h5><p>因为HBase以及kafka做集群，所以就需要zookeeper了。 zookeeper 在很多环境搭建上，都会有他的身影，如kafka、storm等，这里就不多说了。</p><ol><li><p>文件准备 将下载下来的Zookeeper 的配置文件进行解压 在linux上输入: tar -xvf zookeeper-3.4.10.tar.gz 然后移动到/opt/zookeeper里面，没有就新建，然后将文件夹重命名为zookeeper3.4 输入 mkdir /opt/zookeeper mv zookeeper-3.4.10 /opt/zookeeper/zookeeper3.4</p></li><li><p>修改配置文件 2.1 创建文件和目录 在集群的服务器上都创建这些目录 mkdir /opt/zookeeper/data mkdir /opt/zookeeper/dataLog 并且在/opt/zookeeper/data目录下创建myid文件 输入: touch myid 创建成功之后，更改myid文件。 我这边为了方便，将master、slave1、slave2的myid文件内容改为1,2,3 2.2 新建zoo.cfg 切换到/opt/zookeeper/zookeeper3.4/conf 目录下 如果没有 zoo.cfg 该文件，就复制zoo_sample.cfg文件并重命名为zoo.cfg。 修改这个新建的zoo.cfg文件</p><p>dataDir=/opt/zookeeper/data dataLogDir=/opt/zookeeper/dataLog server.1=master:2888:3888 server.2=slave1:2888:3888 server.3=slave2:2888:3888</p></li></ol><p>配置说明： client port，顾名思义，就是客户端连接zookeeper服务的端口。这是一个TCP port。 dataLogDir里是放到的顺序日志(WAL)。而dataDir里放的是内存数据结构的snapshot，便于快速恢复。为了达到性能最大化，一般建议把dataDir和dataLogDir分到不同的磁盘上，这样就可以充分利用磁盘顺序写的特性。dataDir和dataLogDir需要自己创建，目录可以自己制定，对应即可。 server.1中的这个1需要和master这个机器上的dataDir目录中的myid文件中的数值对应。server.2中的这个2需要和slave1这个机器上的dataDir目录中的myid文件中的数值对应。server.3中的这个3需要和slave2这个机器上的dataDir目录中的myid文件中的数值对应。当然，数值你可以随便用，只要对应即可。2888和3888的端口号也可以随便用，因为在不同机器上，用成一样也无所谓。 其他配置说明： 1.tickTime：CS通信心跳数 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。 tickTime=2000 2.initLimit：LF初始通信时限 集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。 initLimit=10 3.syncLimit：LF同步通信时限 集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。 syncLimit=5 依旧将zookeeper传输到其他的机器上，记得更改 /opt/zookeeper/data 下的myid，这个不能一致。 输入: scp -r /opt/zookeeper root@slave1:/opt scp -r /opt/zookeeper root@slave2:/opt 修改myid 3. 启动zookeeper 因为zookeeper是选举制，它的主从关系并不是像hadoop那样指定的，具体可以看官方的文档说明。 成功配置zookeeper之后，在每台机器上启动zookeeper。 切换到zookeeper目录下 cd /opt/zookeeper/zookeeper3.4/bin 输入: zkServer.sh start 成功启动之后 查看状态输入: zkServer.sh status 可以查看各个机器上zookeeper的leader和follower ，只能一个是主，随机选择，入下图：</p><h5 id="hbase的环境配置" tabindex="-1">HBase的环境配置 <a class="header-anchor" href="#hbase的环境配置" aria-label="Permalink to &quot;HBase的环境配置&quot;">​</a></h5><ol><li><p>文件准备 将下载下来的HBase的配置文件进行解压 在linux上输入: tar -xvf hbase-1.2.6-bin.tar.gz 然后移动到/opt/hbase 文件夹里面，并重命名为 hbase1.2 输入 mkdir /opt/hbase mv hbase-1.2.6 /opt/hbase/hbase1.2</p></li><li><p>修改配置文件 切换到 /opt/hbase/hbase1.2/conf下 2.1 修改hbase-env.sh 编辑 hbase-env.sh 文件，添加以下配置</p><p>export JAVA_HOME=/opt/java/jdk1.8 export HADOOP_HOME=/opt/hadoop/hadoop2.8 export HBASE_HOME=/opt/hbase/hbase1.2 export HBASE_CLASSPATH=/opt/hadoop/hadoop2.8/etc/hadoop export HBASE_PID_DIR=/root/hbase/pids export HBASE_MANAGES_ZK=false</p></li></ol><p>说明:配置的路径以自己的为准。HBASE_MANAGES_ZK=false 是不启用HBase自带的Zookeeper集群。 2.2 修改 hbase-site.xml</p><p>说明:hbase.rootdir：这个目录是region server的共享目录，用来持久化Hbase 。hbase.cluster.distributed ：Hbase的运行模式。false是单机模式，true是分布式模式。若为false,Hbase和Zookeeper会运行在同一个JVM里面。 2.3 修改regionservers 指定hbase的主从，和hadoop的slaves文件配置一样 将文件修改为 slave1 slave2 注:上面的为集群的主机名称 在一台机器上(最好是master)做完这些配置之后，我们使用scp命令将这些配置传输到其他机器上。 输入: hbase环境传输 scp -r /opt/hbase root@slave1:/opt scp -r /opt/hbase root@slave2:/opt 传输之后，在主节点启动集群。 3. 启动hbase 在成功启动Hadoop、zookeeper之后 切换到HBase目录下 cd /opt/hbase/hbase1.2/bin 输入: start-hbase.sh 启动成功之后，可以使用jps命令在各个机器上查看是否成功 可以在浏览器输入: ip+16010 端口查看 <a href="http://master:16010/master-status" target="_blank" rel="noreferrer">http://master:16010/master-status</a> 若成功显示该界面，则启动成功。</p><h5 id="mysql安装" tabindex="-1">Mysql安装 <a class="header-anchor" href="#mysql安装" aria-label="Permalink to &quot;Mysql安装&quot;">​</a></h5><p>因为Hive的默认元数据是Mysql，所以先要安装Mysql。 Mysql有两种安装模式，可自行选择。</p><ol><li>yum安装mysql 首先查看mysql 是否已经安装 输入： rpm -qa | grep mysql 如果已经安装，想删除的话 输入: 普通删除命令: rpm -e mysql 强力删除命令: rpm -e --nodeps mysql 依赖文件也会删除 安装mysql 输入: yum -y install mysql mysql-server mysql-devel</li><li>启动和配置mysql 安装成功后，输入 service mysqld start 启动服务 输入之后直接回车(默认是没有密码的) 然后再输入 mysql -u root -p 通过授权法更改远程连接权限 输入: mysql&gt; GRANT ALL PRIVILEGES ON <em>.</em> TO &#39;root&#39;@&#39;%&#39;IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION; 注:第一个’root’是用户名,第二个’%’是所有的ip都可以远程访问,第三个’123456’表示 用户密码 如果不常用 就关闭掉 use mysql; update user set password=passworD(&quot;123456&quot;) where user=&#39;root&#39;; 输入:flush privileges; 可以使用navcat之类的工具测试是否能正确连接 将mysql设置为开机启动 chkconfig mysqld on</li></ol><h5 id="hive环境安装和配置" tabindex="-1">Hive环境安装和配置 <a class="header-anchor" href="#hive环境安装和配置" aria-label="Permalink to &quot;Hive环境安装和配置&quot;">​</a></h5>',34)),i("ol",null,[e[16]||(e[16]=i("li",null,[i("p",null,"文件准备 将下载下来的Hive 的配置文件进行解压 在linux上输入: tar -xvf apache-hive-2.1.1-bin.tar.gz 然后移动到/opt/hive 里面，将文件夹重命名为 hive2.1 输入 mkdir /opt/hive mv apache-hive-2.1.1-bin /opt/hive/hive2.1")],-1)),i("li",null,[e[15]||(e[15]=n("<p>配置更改 2.1 新建文件夹 在修改配置文件之前，需要先在root目录下建立一些文件夹。 mkdir /root/hive mkdir /root/hive/warehouse 新建完该文件之后，需要让hadoop新建/root/hive/warehouse 和 /root/hive/ 目录。 执行命令： <em>H__A__D__O__O__P__H_​_O__M__E</em>/<em>b__i__n</em>/<em>h__a__d__o__o__p__f__s</em>−<em>m__k__d__i__r</em>−<em>p</em>/<em>r__o__o__t</em>/<em>h__i__v__e</em>/HADOOP_HOME/bin/hadoop fs -mkdir -p /root/hive/warehouse 给刚才新建的目录赋予读写权限，执行命令： <em>H__A__D__O__O__P__H_​_O__M__E</em>/<em>b__i__n</em>/<em>h__a__d__o__o__p__f__s</em>−_c__h__m__o__d_777/<em>r__o__o__t</em>/<em>h__i__v__e</em>/HADOOP_HOME/bin/hadoop fs -chmod 777 /root/hive/warehouse 检查这两个目录是否成功创建 输入: <em>H__A__D__O__O__P__H_​_O__M__E</em>/<em>b__i__n</em>/<em>h__a__d__o__o__p__f__s</em>−<em>l__s</em>/<em>r__o__o__t</em>/HADOOP_HOME/bin/hadoop fs -ls /root/hive/ 可以看到已经成功创建 2.2 修改hive-site.xml 切换到 /opt/hive/hive2.1/conf 目录下 将hive-default.xml.template 拷贝一份，并重命名为hive-site.xml 然后编辑hive-site.xml文件 cp hive-default.xml.template hive-site.xml vim hive-site.xml 编辑hive-site.xml文件:</p>",1)),a(p,null,{default:o(()=>[a(r,null,{default:o(()=>e[0]||(e[0]=[t("hive.metastore.warehouse.dir")])),_:1}),a(s,null,{default:o(()=>e[1]||(e[1]=[t("/root/hive/warehouse")])),_:1})]),_:1}),a(p,null,{default:o(()=>[a(r,null,{default:o(()=>e[2]||(e[2]=[t("hive.exec.scratchdir")])),_:1}),a(s,null,{default:o(()=>e[3]||(e[3]=[t("/root/hive")])),_:1})]),_:1}),a(p,null,{default:o(()=>[a(r,null,{default:o(()=>e[4]||(e[4]=[t("hive.metastore.uris")])),_:1}),a(s)]),_:1}),a(p,null,{default:o(()=>[a(r,null,{default:o(()=>e[5]||(e[5]=[t("javax.jdo.option.ConnectionURL")])),_:1}),a(s,null,{default:o(()=>e[6]||(e[6]=[t("jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true")])),_:1})]),_:1}),a(p,null,{default:o(()=>[a(r,null,{default:o(()=>e[7]||(e[7]=[t("javax.jdo.option.ConnectionDriverName")])),_:1}),a(s,null,{default:o(()=>e[8]||(e[8]=[t("com.mysql.jdbc.Driver")])),_:1})]),_:1}),a(p,null,{default:o(()=>[a(r,null,{default:o(()=>e[9]||(e[9]=[t("javax.jdo.option.ConnectionUserName")])),_:1}),a(s,null,{default:o(()=>e[10]||(e[10]=[t("root")])),_:1})]),_:1}),a(p,null,{default:o(()=>[a(r,null,{default:o(()=>e[11]||(e[11]=[t("javax.jdo.option.ConnectionPassword")])),_:1}),a(s,null,{default:o(()=>e[12]||(e[12]=[t("123456")])),_:1})]),_:1}),a(p,null,{default:o(()=>[a(r,null,{default:o(()=>e[13]||(e[13]=[t("hive.metastore.schema.verification")])),_:1}),a(s,null,{default:o(()=>e[14]||(e[14]=[t("false")])),_:1}),a(h)]),_:1})])]),e[18]||(e[18]=n(`<p>然后将配置文件中所有的 {system:java.io.tmpdir} 更改为 /opt/hive/tmp (如果没有该文件则创建)， 并将此文件夹赋予读写权限， 将{system:user.name}更改为 root 注: 由于hive-site.xml 文件中的配置过多，可以通过FTP将它下载下来进行编辑。也可以直接配置自己所需的，其他的可以删除。 MySQL的连接地址中的master是主机的别名，可以换成ip。 2.3 修改 hive-env.sh 修改hive-env.sh 文件，没有就复制 hive-env.sh.template ，并重命名为hive-env.sh 在这个配置文件中添加</p><pre><code>export  HADOOP_HOME=/opt/hadoop/hadoop2.8
export  HIVE_CONF_DIR=/opt/hive/hive2.1/conf
export  HIVE_AUX_JARS_PATH=/opt/hive/hive2.1/lib
</code></pre><p>2.4 添加 数据驱动包 由于Hive 默认自带的数据库是使用mysql，所以这块就是用mysql 将mysql 的驱动包 上传到 /opt/hive/hive2.1/lib cp /home/hsy/mysql-connector-java-5.1.41.jar /opt/hive/hive2.1/lib/ 3. Hive Shell 测试 在成功启动Hadoop之后 切换到Hive目录下 输入: cd /opt/hive/hive2.1/bin 3.1 首先初始化数据库 初始化的时候注意要将mysql启动 输入: schematool -initSchema -dbType mysql 执行成功之后，可以看到hive数据库和一堆表已经创建成功了 3.2 启动hive 进入hive (确保hadoop以及成功启动)输入: hive 进入hive 之后 做一些简单的操作 新建一个库，然后在建一张表 基本操作和普通的关系型数据库差不多 创建库: create database db_chenjian; 创建表: create table db_chenjian.student(id int,name string) row format delimited fields terminated by &#39; &#39;; 3.3 加载数据 新打开一个窗口 因为hive 不支持写，所以添加数据使用load加载文本获取。 新建一个文本 touch /opt/hive/student.txt 编辑该文本添加数据 输入: vim /opt/hive/student.txt 添加数据: 中间的空格符使用Tab建 1001 zhangsan 1002 lisi 1003 wangwu 说明: 文本可以在Windows上面新建，然后通过ftp上传到linux中，需要注意文本的格式为unix 格式。 切换到hive shell 加载数据 输入: load data local inpath &#39;/opt/hive/student.txt&#39; into table db_chenjian.student; 3.4 查询该数据 输入： select * from db_chenjian.student;</p><h5 id="安装配置kafka" tabindex="-1">安装配置kafka <a class="header-anchor" href="#安装配置kafka" aria-label="Permalink to &quot;安装配置kafka&quot;">​</a></h5><ol><li><p>文件准备 将下载下来的kafka 的安装文件进行解压 在linux上输入: tar -zxvf kafka_2.12-1.0.0.tgz 然后移动到/opt/kafka里面，没有就新建， 输入 mkdir /opt/kafka mv kafka_2.12-1.0.0 /opt/kafka/kafka1.0.0</p></li><li><p>修改配置文件 修改master机器配置文件 /opt/kafka/kafka1.0.0/config/server.properties</p><pre><code> broker.id=0  标示符(多台服务器标示符0,1,2,3，...依次增长)
 host.name=master 绑定的主机
 log.dirs= /opt/kafka/kafka1.0.0/kafka-logs  数据保存的位置
 log.retention.hours=168  数据的保留时间
 zookeeper.connect=master:2181,slave1:2181,slave2:2181
</code></pre></li></ol><p>将本机kafka拷贝至其他机器，此处只选用了两台机器master和slave1，执行下面的命令： scp -r /opt/kafka/ root@slave1:/opt/ 修改slave1配置文件 /opt/kafka/kafka1.0.0/config/server.properties</p><pre><code>    broker.id=1  标示符(多台服务器标示符0,1,2,3，...依次增长)
    host.name=slave1 绑定的主机
</code></pre><p>启动kafka a.启动zookeeper集群 b.启动服务的命令(两台机器都执行) nohup /opt/kafka/kafka1.0.0/bin/kafka-server-start.sh /opt/kafka/kafka1.0.0/config/server.properties &amp; c.创建主题 /opt/kafka/kafka1.0.0/bin/kafka-topics.sh --create --zookeeper master:2181,slave1:2181 --replication-factor 1 --partitions 1 --topic chenjian d.查看当前有哪些主题： /opt/kafka/kafka1.0.0/bin/kafka-topics.sh --list --zookeeper master:2181,slave1:2181,slave2:2181 3. 测试kafka 3.1 模拟发送数据 /opt/kafka/kafka1.0.0/bin/kafka-console-producer.sh --broker-list slave1:9092,slave2:9092 --topic chenjian 3.2 消费数据 /opt/kafka/kafka1.0.0/bin/kafka-console-consumer.sh --zookeeper master:2181,slave1:2181,slave2:2181 --from-beginning --topic chenjian 在模拟发送数据窗口输入，就会看到在消费端有相应的数据。</p>`,8))])}const O=d(_,[["render",v]]);export{g as __pageData,O as default};
